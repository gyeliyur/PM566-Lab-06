---
title: "LAB-6"
author: "Gowri"
format:
  html:
    embed-resources: true
fig-height: 10
fig-width: 10
editor: visual
---

```{r}
#package set up 
library(tidytext)
```

### **Read in Medical Transcriptions**

```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)

mt_samples <- read_csv("https://raw.githubusercontent.com/USCbiostats/data-science-data/master/00_mtsamples/mtsamples.csv")
mt_samples <- mt_samples |>
  select(description, medical_specialty, transcription)

head(mt_samples)

```

## **Question 1: What specialties do we have?**

Use the `count()` function from `dplyr` to figure out how many different categories we have in the data. Are these categories related? Overlapping? Evenly distributed?

answer: 40 categories are there , some categories are related, they are not evenly distributed

```{r}
mt_samples %>%
  count(medical_specialty, sort = TRUE)
```

## **Question 2**

most frequent words are the stop words. This make sense as the, and , was words are commonly used in sentences. \
stop words need to be removed and analysed again

```{r}
mt_samples %>%
  unnest_tokens(word, transcription) %>%
  count(word, sort = TRUE) %>%
  top_n(20, n) %>%
  ggplot(aes(x = reorder(word, n), y = n)) +
           geom_col() +
           coord_flip() +
           labs(x = "Word", y = "Count", title = "top 20 most frequent words")
```

## **Question 3**

patient is the most frequently used word.

```{r}
mt_samples %>%
  unnest_tokens(word, transcription) %>%
  anti_join(stop_words %>% filter(!word %in% c("right", "left")), by ="word") %>%
  filter(!grepl("^[0-9]+$", word)) %>%
  count(word, sort = TRUE) %>%
  top_n(20, n) %>%
  ggplot(aes(x = reorder(word, n), y = n)) +
           geom_col() +
           coord_flip() +
           labs(x = "Word", y = "Count", title = "top 20 most frequent words")
```

# **Question 4**

answer :

```{r}
#Bi-grams 
mt_samples %>%
  unnest_tokens(bigram, transcription, token ="ngrams", n = 2) %>%
  count(bigram, sort = TRUE) %>%
  top_n(20, n) 

  #Tri-grams
  mt_samples %>%
  unnest_tokens(trigram, transcription, token = "ngrams", n = 3 ) %>%
  count(trigram, sort = TRUE) %>%
  top_n(20, n) 
  
```

# **Question 5**

```{r}
mt_samples %>%
  unnest_tokens(bigram, transcription, token ="ngrams", n = 2) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  filter(word1 == "patient" | word2 == "pateint") %>%
  count(word1, word2, sort = TRUE) 

```

# **Question 6**

```{r}
# top 5 word used for each speciality 
mt_samples %>%
  unnest_tokens(word, transcription) %>%
  anti_join(stop_words %>% filter(!word %in% c("right", "left")), by ="word") %>%
  filter(!grepl("^[0-9]+$", word)) %>%
  group_by(medical_specialty) %>%
  count(word, sort = TRUE) %>%
  top_n(5, n) %>%
arrange(medical_specialty, desc(n))

mt_samples %>%
  unnest_tokens(word, transcription) %>%
  anti_join(stop_words , by ="word") %>%
  filter(!grepl("^[0-9]+$", word)) %>%
  group_by(medical_specialty) %>%
  count(word, sort = TRUE) %>%
  top_n(5, n) %>%
arrange(medical_specialty, desc(n))
```

# **Question 7 - extra**

```{r}
#compare word usage in top 5 specialities 
top_specialties <- mt_samples %>%
  count(medical_specialty, sort = TRUE) %>%
  top_n(5,n) %>%
  pull(medical_specialty)

mt_samples %>%
  filter(medical_specialty %in% top_specialties) %>%
  unnest_tokens(word, transcription) %>%
  anti_join(stop_words, by = "word") %>%
  filter(!grepl("^[0-9]+$", word)) %>%
  group_by(medical_specialty, word) %>%
  summarise(n = n(), .groups = "drop") %>%
  group_by(medical_specialty) %>%
  top_n(10, n) %>%
  ungroup() %>%
  mutate(word = reorder_within(word, n, medical_specialty)) %>%
  ggplot(aes(x= n, y = word, fill = medical_specialty)) +
  geom_col() +
  scale_y_reordered() +
  facet_wrap(~medical_specialty, scales = "free_y") +
  labs(x = "count", y = "word", title = "top 10 words by speciality") +
  theme(legend.position = "none")
```
